---
title: "Script"
author: "Mariana Rius"
date: "4/24/2020"
output: html_document
---

# Setup

1. Install on your own computer:

[R](https://www.r-project.org/)

[RStudio](https://rstudio.com/products/rstudio/download/)

1. In console run:

```{r setup}

knitr::opts_knit$set(root.dir = "C:/Users/alexg/Google Drive/05-Proyectos/restlab_workshop/MarianaRius")

```


install.packages("readxl")
install.packages("rlist")
install.packages("growthcurver")
install.packages("dplyr")
install.packages("ggplot2")



1. Download datasets or locate your own data you would like to use.

IMPORTANT: For the script to run properly an independent folder containing the data file is 

# Datasets provided:

## LAA-E2.xlsx

- OD data - Single reads per well
- LAA = Laby Antibiotic Assay
  - [plate setup](https://docs.google.com/presentation/d/1jRHy32pm0gParXaoHVKo8pyVgZAvbHmZJvZlcpzZYKc/edit?usp=sharing)
  - 96 wells
  - 16 time points
  - No media blank
- Excel file
  - sheets arranged reverse chronologically (most recent **first** )
  - OD reads start at row 27 (header = row 26)
  - Date and time on row 23
  - Last sheet is not blank

## NGE-E1-P3.xlsx

- OD Data - Multiple reads per well
- NGE = Nutrient Growth Experiment
  - [plate setup](https://docs.google.com/presentation/d/1Fe_pQ2ebTqtWHqC9wkUPmBWrXytWQm8loQvxyXw0EWs/edit?usp=sharing)
  - 96 wells
  - 6 time points
  - No media blank
- Excel file
  - Sheets arranged reverse chronologically (most recent **first** )
  - OD reads start at row 48 (header = row 47)
  - Date and time on row 25
  - Last sheet is blank


# Growthcurver Intro

# Growth phases of a culture

# ![]("figures/RackMultipart20200424-4-1p8fbov_html_490b1408a4bc51ff.png")

Logistic equation (used by growthcurver)

# ![]("figures/RackMultipart20200424-4-1p8fbov_html_289ba352951d9cd3.png")

_N__t_ = population at time _t_

_K_ = carrying capacity

_N__0_ = initial population size

_r_ = intrinsic growth rate

![]("figures/RackMultipart20200424-4-1p8fbov_html_1bbdb586aaf8fd83.png")

# R/ RStudio Orientation

- Script, Console, Environment, Help
- R basics
  - making objects
  - bject types
    - numeric, character, factor, vector, data.frame, list
  - for loop
  - functions
    - c() and trick to building a recursive vector
    - head() and tail()
    -

# Pipeline

We will be following this vignette: [Growthcurver](https://cran.r-project.org/web/packages/growthcurver/vignettes/Growthcurver-vignette.html)

## Pipeline breakdown:

1. Setup script
2. Load data
3. Organize data for growthcurver

1. Run growthcurver
2. Plot growthcurver output
3. PCA &amp; plot
4. Sigma histogram
5. Plot parameters

##

## LAA-E2.xlsx


### 1. Setup script

```{r}
options(stringsAsFactors = F)
#total wells
tw<-96
#filename
fn<-"data/LAA-E2//LAA-E2.xlsx"
#replicates?
x<-3
#number of antibiotic concentrations
nc<-12
#number of strains #JUST AURLI
ns<-1
```

############
### 2. Load data
```{r}
library("readxl")
allSheets<-list()
for (i in 1:c((length(excel_sheets(fn))))){   #This will read in each sheet of excel file 'fn', if there is a blank sheet at the end of excel file this line will be "for (i in 1:c((length(excel_sheets(fn)))-1)){" 
mySheet <- read_excel(fn, sheet = i)  #This will import a sheet as a dataframe 
  write.csv(mySheet, file = paste("t", i,".csv", sep = ""), row.names = FALSE)   #This will save each sheet as a csv with the file name 't.x', x = sheet number 
  mySheet<-read.csv(paste("t", paste(i),".csv", sep= ""), header = T, skip = 25, stringsAsFactors=FALSE) #This will read in the data starting at the line number after 'skip='
  mySheet<-mySheet[,2:13] #This will filter out your data [row,column], removing row names
  allSheets[[i]]<-mySheet[1:3,] #preserved only first three rows (aurli) and stored data as a list element in allSheets 
}
```


what does allSheets look like?
```{r}
head(allSheets)
```



### 3. Organize data for growthcurver

```{r}
#reverse list order for excel files in reverse chronological order
library("rlist")
allSheets1<-list.reverse(allSheets)

#calculate difference in time
sto1.t<-list()
for (i in 1:c(length(excel_sheets(fn)))) {
  sto.t<-read.csv(paste("t", paste(i),".csv", sep= ""), header = F, skip = 22, nrow = 1, stringsAsFactors=FALSE)
  #date & time
  sto.t<-sto.t[1,2]
  #strsplit date & replace "/" with "-"
  date<-gsub("/", "-", paste((strsplit(sto.t, " ")[[1]][(1)]), collapse = " "))
  #date format from m-d-y to y-m-d
  y<-(strsplit(date, "-")[[1]][(3)])
  m<-(strsplit(date, "-")[[1]][(1)])
  d<-(strsplit(date, "-")[[1]][(2)])
  tdate<-paste(y, m,d, sep = "-")
  #put into list
  sto1.t[[i]]<-tdate
  #strsplit time
  t<-paste((strsplit(sto.t, " ")[[1]][(2:3)]), collapse = " ")
  #change 12H to 24H
  ttime<-format(strptime(t, "%I:%M:%S %p"), format="%H:%M:%S")
  sto1.t[[i]][2]<-ttime
}
sto1.t<-list.reverse(sto1.t)
tdif<-c()
for (i in 2:length(sto1.t)) {
  dif<-difftime(paste(sto1.t[[i]][1],sto1.t[[i]][2], sep = " "), paste(sto1.t[[1]][1],sto1.t[[1]][2], sep = " "), units = "hours")
  tdif<-c(tdif, dif)
}
tdif<-c(0,tdif)
```

what does tdif look like?

```{r}
#create the data.frame structure and column names
u<-data.frame(time=c(tdif))
ro<-c("A","B","C")
co<-c(1:12)

df<-c() #makes a vector of all the well names used in 'ro' and 'co'
for (i in (unique(ro))) {
  for (j in (unique(co))) {
    df<-c(df,paste(i,j,sep=""))
  }
}

for (i in 1:length(df)) { #creates each well name to be a vector in existence
  assign(df[i], c(recursive = TRUE))
}

for (i in 1:length(df)) { #assigns vector of well name and column of u with data of each time point at well placement
  for (j in 1:length(allSheets1)) {
    assign(df[i], c(get(df[i]),as.numeric(c(allSheets1[[j]][1,],allSheets1[[j]][2,],allSheets1[[j]][3,]))[i])) # makes a vector of data to sleect based on df[i] // optimization required here for more than three rows 
  }
  u[,(i+1)]<-get(df[i])
}

colnames(u)<-c("time",df) #give each column the corresponding well name
```

what does u look like?

### 4.Run growthcurver

```{r}
library("growthcurver")
gc_out <- SummarizeGrowthByPlate(u)
```



what does gc_out look like?

Additional parameters provided in gc\_out

t\_mid _= t, Â½ K,_ the time at which the population density reaches half the carrying capacity

t\_gen = doubling time, the least amount of time required to double the population

auc\_l = the area under the modeled logistic curve (integral of the logistic equation)

auc\_e = the area under the curve obtained from the optical density readings data

sigma = residual standard deviation, the estimated standard deviation of the errors // residual sum of squares from the fit of the logistic curve to the data, so larger values mean poorer fits, a parameter used to evaluate the &#39;goodness of fit&#39;

```{r}
gc_out$note?  unique(gc_out$note) 
save gc_out?  
write.csv(gc_out,file="aurli_growthcurver_output.csv") 
save(gc_out,file="aurli_growthcurver_output.rda")
```


### 6. Plot growthcurver output
```{r}
d<-u #renames our data to match growthcurver's provided script

num_analyses <- length(names(d)) - 1
d_gc <- data.frame(sample = character(num_analyses),
                   k = numeric(num_analyses),
                   n0  = numeric(num_analyses),
                   r = numeric(num_analyses),
                   t_mid = numeric(num_analyses),
                   t_gen = numeric(num_analyses),
                   auc_l = numeric(num_analyses),
                   auc_e = numeric(num_analyses),
                   sigma = numeric(num_analyses),
                   stringsAsFactors = FALSE)

trim_at_time<-tdif[8] #set our preferred plotting range based on tdif
#pdf("LAA-E2_growthcurver_r.pdf", height = 8.5, width = 11) #to print a pdf remove the hashtag at this line AND at line below = 'dev.off()' 
par(mfrow = c(8,12))
par(mar = c(0.25,0.25,0.25,0.25))
y_lim_max <- max(d[,setdiff(names(d), "time")]) - min(d[,setdiff(names(d), "time")])

n <- 1    # keeps track of the current row in the output data frame
for (col_name in names(d)) {
  
  # Don't process the column called "time". 
  # It contains time and not absorbance data.
  if (col_name != "time") {
    
    # Create a temporary data frame that contains just the time and current col
    d_loop <- d[, c("time", col_name)]
    
    # Do the background correction.
    # Background correction option 1: subtract the minimum value in a column
    #                                 from all measurements in that column
    min_value <- min(d_loop[, col_name])
    d_loop[, col_name] <- d_loop[, col_name] - min_value
    # Background correction option 2: subtract the mean value of blank wells
    #                                 over the course the experiment
    #                                 (Replace B2, D8, G11 with the column
    #                                  names of your media-only wells)
    #d$blank <- apply(d[, c("B2", "D8", "G11")], 1, mean)
    #d$A1 <- d$A1 - d$blank
    
    # Now, call Growthcurver to calculate the metrics using SummarizeGrowth
    gc_fit <- SummarizeGrowth(data_t = d_loop[, "time"], 
                              data_n = d_loop[, col_name],
                              t_trim = trim_at_time,
                              bg_correct = "none")
    
    # Now, add the metrics from this column to the next row (n) in the 
    # output data frame, and increment the row counter (n)
    d_gc$sample[n] <- col_name
    d_gc[n, 2:9] <- c(gc_fit$vals$k,
                      gc_fit$vals$n0,
                      gc_fit$vals$r,
                      gc_fit$vals$t_mid,
                      gc_fit$vals$t_gen,
                      gc_fit$vals$auc_l,
                      gc_fit$vals$auc_e,
                      gc_fit$vals$sigma)
    n <- n + 1
    
    # Finally, plot the raw data and the fitted curve
    # Here, I'll just print some of the data points to keep the file size smaller
    n_obs <- length(gc_fit$data$t)
    idx_to_plot <- 1:20 / 20 * n_obs
    plot(gc_fit$data$t[idx_to_plot], gc_fit$data$N[idx_to_plot], 
         pch = 20, 
         xlim = c(0, trim_at_time), 
         ylim = c(0, y_lim_max),
         cex = 0.6, xaxt = "n", yaxt = "n")
    text(x = trim_at_time / 4, y = y_lim_max, labels = col_name, pos = 1)
    if (gc_fit$model=="") {
      gc_fit$model<-rep(0,length(tdif[1:grep(trim_at_time, tdif)])-1)
      lines(gc_fit$data$t, rep(0,length(tdif[1:grep(trim_at_time, tdif)])-1), col = "indianred3")
    }
    else #I added 'if...else' for data where no model was fit plots line at y=0
      lines(gc_fit$data$t, predict(gc_fit$model), col = "indianred3")
  }
}

#dev.off() #to print a pdf remove the hashtag at this line AND at 'pdf(...)' line above

```


### 6. PCA and plot

```{r}
# Load dplyr, ggplot2, and the sample data
library(dplyr)
library(ggplot2)
pca_gc_out <- as_data_frame(gc_out) 

# Prepare the gc_out data for the PCA
rownames(pca_gc_out) <- pca_gc_out$sample
# Do the PCA
pca.res <- prcomp(pca_gc_out %>% select(k:sigma), center=TRUE, scale=TRUE)
# Plot the results
as_data_frame(list(PC1=pca.res$x[,1],
                   PC2=pca.res$x[,2],
                   samples = rownames(pca.res$x))) %>% 
  ggplot(aes(x=PC1,y=PC2, label=samples)) + 
  geom_text(size = 3)



# Do the PCA with percentages in axes
pca.res <- prcomp(pca_gc_out %>% select(k:sigma), center=TRUE, scale=TRUE)
percentage <- round(pca.res$sdev / sum(pca.res$sdev) * 100, 2)
df_out <- as.data.frame(pca.res$x)
percentage <- paste( colnames(df_out), "(", paste( as.character(percentage), "%", ")", sep="") )
# Plot the results
as_data_frame(list(PC1=pca.res$x[,1],
                   PC2=pca.res$x[,2],
                   samples = rownames(pca.res$x))) %>% 
  ggplot(aes(x=PC1,y=PC2, label=samples)) + geom_text(size = 3) + xlab(percentage[1]) + ylab(percentage[2])

```

### 7. Sigma histogram

```{r}
par(mfrow=c(1,1),mar = c(3.8,3.8,2,2))
# Plot a histogram of the sigma values in order to check for outliers
hist(gc_out$sigma, breaks= 30,main = "Histogram of sigma values", xlab = "sigma", col = "palegreen3", xlim = c(0, max(gc_out$sigma)))

```

### 8. Plot parameters

```{r}
par(mfrow = c(8,12))
par(mar = c(0.25,0.25,0.25,0.25))

y<-c(min(gc_out$k), max(gc_out$k))
for (i in 1:12) {
  boxplot(gc_out$k[c(i,i+12, i+24)], col="maroon", ylim=y, yaxt="n")
}

y<-c(min(gc_out$r), max(gc_out$r))
for (i in 1:12) {
  boxplot(gc_out$r[c(i,i+12, i+24)], col="light coral", ylim=y,yaxt="n")
}

y<-c(min(gc_out$t_mid), max(gc_out$t_mid))
for (i in 1:12) {
  boxplot(gc_out$t_mid[c(i,i+12, i+24)], col="goldenrod3", ylim=y,yaxt="n")
}

y<-c(min(gc_out$t_gen), max(gc_out$t_gen))
for (i in 1:12) {
  boxplot(gc_out$t_gen[c(i,i+12, i+24)], col="midnightblue", ylim=y,yaxt="n")
}

y<-c(min(gc_out$auc_l), max(gc_out$auc_l))
for (i in 1:12) {
  boxplot(gc_out$auc_l[c(i,i+12, i+24)], col="mediumpurple3", ylim=y,yaxt="n")
}

y<-c(min(gc_out$auc_e), max(gc_out$auc_e))
for (i in 1:12) {
  boxplot(gc_out$auc_e[c(i,i+12, i+24)], col="tomato3", ylim=y,yaxt="n")
}

```

# NGE-E1-P3.xlsx
### 1. Setup script

```{r}
options(stringsAsFactors = F)

#total wells
tw<-96
#filename
fn<-"NGE-E1-P3.xlsx"
#replicates?
x<-1
#number of conditions
nc<-96
#number of strains
ns<-1
```

### 2. Load data
```{r}
#excel file sheets to csv
library("readxl")
allSheets<-list()
for (i in 1:c((length(excel_sheets(fn)))-1)){
  mySheet <- read_excel(fn, sheet = i)  #This will import a sheet as a dataframe starting at datapoints.
  write.csv(mySheet, file = paste("t", i,".csv", sep = ""), row.names = FALSE)   #This will save each sheet with the file name Sheetx, x being whichever sheet number it is
  mySheet<-read.csv(paste("t", paste(i),".csv", sep= ""), header = T, skip = 46, stringsAsFactors=FALSE)
  mySheet<-mySheet[,1:3]
  allSheets[[i]]<-mySheet[1:tw,] 
}
```

### 3. Organize data for growthcurver

```{r}
#calculate difference in time
sto1.t<-list()
for (i in 1:c(length(excel_sheets(fn))-1)) {
  sto.t<-read.csv(paste("t", paste(i),".csv", sep= ""), header = F, skip = 24, nrow = 1, stringsAsFactors=FALSE)
  #date & time
  sto.t<-sto.t[1,2]
  #strsplit date & replace "/" with "-"
  date<-gsub("/", "-", paste((strsplit(sto.t, " ")[[1]][(1)]), collapse = " "))
  #date format from m-d-y to y-m-d
  y<-(strsplit(date, "-")[[1]][(3)])
  m<-(strsplit(date, "-")[[1]][(1)])
  d<-(strsplit(date, "-")[[1]][(2)])
  tdate<-paste(y, m,d, sep = "-")
  #put into list
  sto1.t[[i]]<-tdate
  #strsplit time
  t<-paste((strsplit(sto.t, " ")[[1]][(2:3)]), collapse = " ")
  #change 12H to 24H
  ttime<-format(strptime(t, "%I:%M:%S %p"), format="%H:%M:%S")
  sto1.t[[i]][2]<-ttime
}
sto1.t<-list.reverse(sto1.t)
tdif<-c()
for (i in 2:length(sto1.t)) {
  dif<-difftime(paste(sto1.t[[i]][1],sto1.t[[i]][2], sep = " "), paste(sto1.t[[1]][1],sto1.t[[1]][2], sep = " "), units = "hours")
  tdif<-c(tdif, dif)
}
tdif<-c(0,tdif)

#create the data.frame structure and column names
u<-data.frame(time=c(tdif))
ro<-c("A","B","C","D","E","F","G","H")
co<-c(1:12)
df<-c() #makes a vector of all the well names used in 'ro' and 'co'
for (i in ro) {
  for (j in co) {
    df<-c(df,paste(i,j,sep=""))
  }
}
for (i in 1:length(df)) { #creates each well name to be a vector in existence
  assign(df[i], c(recursive = TRUE))
}

for (i in 1:length(df)) { #assigns vector of well name and column of u with data of each time point at well placement
  for (j in 1:length(allSheets)) {
    assign(df[i], c(get(df[i]),as.numeric(allSheets[[j]][i,2])))#,allSheets1[[j]][2,],allSheets1[[j]][3,]))[i]))#optimization required here for more than three rows 
  }
  u[,(i+1)]<-get(df[i])
}

colnames(u)<-c("time",df) #give each column the corresponding well name
```

### 4. Run growthcurver

```{r}

```


### 5. Plot growthcurver output

```{r}

```

### 6. PCA & plot

```{r}

```

### 7. Sigma histogram

```{r}

```

### 8. Plot parameters

```{r}
library("readxl")
allSheets<-list()
for (i in 1:c((length(excel_sheets(fn)))-1)){   #This will read in each sheet of excel file 'fn', if there is a blank sheet at the end of excel file this line will be "for (i in 1:c((length(excel_sheets(fn)))-1)){" 
mySheet <- read_excel(fn, sheet = i)  #This will import a sheet as a dataframe 
  write.csv(mySheet, file = paste("t", i,".csv", sep = ""), row.names = FALSE)   #This will save each sheet as a csv with the file name 't.x', x = sheet number 
  mySheet<-read.csv(paste("t", paste(i),".csv", sep= ""), header = T, skip = 25, stringsAsFactors=FALSE) #This will read in the data starting at the line number after 'skip='
  mySheet<-mySheet[1:3,] #This will filter out your data [row,column], removing row names
  allSheets[[i]]<-mySheet[1:tw,] #preserved only first three rows (aurli) and stored data as a list element in allSheets 
```


